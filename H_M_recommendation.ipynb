{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary loadings"
      ],
      "metadata": {
        "id": "R9ToQ9f0afmo"
      },
      "id": "R9ToQ9f0afmo"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "OlHppLZpZapN"
      },
      "id": "OlHppLZpZapN",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEGTIKlBZvTt",
        "outputId": "bac3daac-ca79-4a89-b3af-80576a105ab4"
      },
      "id": "tEGTIKlBZvTt",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model of feature recognitions\n",
        "model = load_model('/content/drive/MyDrive/ds_project_dataset/my_model.h5')\n",
        "\n",
        "# Lists of the class labels\n",
        "colour_lst = \\\n",
        "    ['Beige', 'Black', 'Blue', 'Brown',\n",
        "       'Green', 'Grey', 'Metal', 'Mole',\n",
        "       'Orange', 'colour_Pink', 'Purple', 'Red',\n",
        "       'Turquoise', 'White', 'Yellow']\n",
        "\n",
        "product_lst = \\\n",
        "    ['Bags', 'Garment Full body',\n",
        "       'Garment Lower body', 'Garment Upper body',\n",
        "       'Shoes', 'Socks & Tights', 'Underwear']\n",
        "\n",
        "pattern_lst = \\\n",
        "    ['pattern_All over pattern', 'pattern_Application/3D', 'pattern_Argyle',\n",
        "       'pattern_Chambray', 'pattern_Check', 'pattern_Colour blocking',\n",
        "       'pattern_Contrast', 'pattern_Denim', 'pattern_Dot',\n",
        "       'pattern_Embroidery', 'pattern_Front print',\n",
        "       'pattern_Glittering/Metallic', 'pattern_Hologram', 'pattern_Jacquard',\n",
        "       'pattern_Lace', 'pattern_Melange', 'pattern_Mesh', 'pattern_Metallic',\n",
        "       'pattern_Mixed solid/pattern', 'pattern_Neps',\n",
        "       'pattern_Placement print', 'pattern_Sequin', 'pattern_Slub',\n",
        "       'pattern_Solid', 'pattern_Stripe', 'pattern_Transparent',\n",
        "       'pattern_Treatment']\n",
        "\n",
        "index_lst = \\\n",
        "    ['Divided', 'Ladieswear', 'Menswear']\n",
        "\n",
        "class_labels_dict = {'colour': colour_lst,\n",
        "                     'product': product_lst,\n",
        "                     'pattern': pattern_lst,\n",
        "                     'index': index_lst}\n",
        "                     \n",
        "# Load model ResNet50 for embedding vectors calculation\n",
        "resnet_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "# Load the cloth items from the database with correpondent features an embedding vectors\n",
        "df = pd.read_parquet('/content/drive/MyDrive/ds_project_dataset/embeddings_df.parquet')\n",
        "\n",
        "def get_image_path_by_id(id):\n",
        "    \"\"\"\n",
        "    Returns image_path correspondent to id (e.g. 220094021)\n",
        "    \"\"\"\n",
        "    shared_folder_path = '/content/drive/MyDrive/ds_project_dataset/'\n",
        "    id = str(id) \n",
        "    return shared_folder_path + 'images/' + '0'+id[:2]+'/0' + id + '.jpg'"
      ],
      "metadata": {
        "id": "i2QxiezJZ2oP"
      },
      "id": "i2QxiezJZ2oP",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function"
      ],
      "metadata": {
        "id": "KehdOnzTZYz1"
      },
      "id": "KehdOnzTZYz1"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(user_image):\n",
        "  \"\"\"\n",
        "  Get recommendations similar/complementary based on the given user_image\n",
        "  \"\"\"\n",
        "  # Resize the image to 80x80\n",
        "  IMG_SIZE_FOR_RECOGNITION = 80\n",
        "  user_image_for_recognition = cv2.resize(user_image, (IMG_SIZE_FOR_RECOGNITION, IMG_SIZE_FOR_RECOGNITION))\n",
        "  \n",
        "  # Get probabilities of the classes\n",
        "  color_pred, type_pred, pattern_pred, index_pred = model.predict(np.array([user_image_for_recognition]))\n",
        "\n",
        "  # Save the recognized features to the Dictionary\n",
        "  pred_imag_dict = {\n",
        "                    'product_group_name': class_labels_dict['product'][np.argmax(type_pred)],\n",
        "                    'index_group_name': class_labels_dict['index'][np.argmax(index_pred)],\n",
        "                    'perceived_colour_master_name': class_labels_dict['colour'][np.argmax(color_pred)]\n",
        "                      }\n",
        "\n",
        "  # Resize the image to 224x224\n",
        "  IMG_SIZE_FOR_EMBEDDING = 224\n",
        "  user_image_for_embedding = cv2.resize(user_image, (IMG_SIZE_FOR_EMBEDDING, IMG_SIZE_FOR_EMBEDDING))\n",
        "\n",
        "  # Add an extra batch dimension to the image\n",
        "  user_image_for_embedding = np.expand_dims(user_image_for_embedding, axis=0)\n",
        "\n",
        "  # Pass the image through the ResNet50 model\n",
        "  features = resnet_model.predict(user_image_for_embedding)\n",
        "\n",
        "  # Extract the embedding from the output of the model\n",
        "  embeddings = features.squeeze()\n",
        "\n",
        "  # Add embedding to the dictionary\n",
        "  pred_imag_dict['embedding'] = embeddings\n",
        "\n",
        "  # Define database to look for similar items\n",
        "  subset_similar = df[(df['product_group_name'] == pred_imag_dict['product_group_name']) & (df['index_group_name'] == pred_imag_dict['index_group_name'])].copy()\n",
        "\n",
        "  # Define database to look for complementary items\n",
        "  subset_comp = df[(df['product_group_name'] != pred_imag_dict['product_group_name']) & (df['index_group_name'] == pred_imag_dict['index_group_name'])].copy()\n",
        "\n",
        "  #### Get recommendation of similar items\n",
        "  # Caluclate similarity scores between user image and images from the database\n",
        "  similarity_scores = []\n",
        "  for array in subset_similar[\"embedding\"]:\n",
        "      array = array.reshape(1, -1)\n",
        "      similarity = cosine_similarity(pred_imag_dict['embedding'].reshape(1, -1), array)\n",
        "      similarity_scores.append(similarity[0][0])\n",
        "  subset_similar['score'] = similarity_scores\n",
        "\n",
        "  # Get TOP 10 similar products\n",
        "  reccs = subset_similar.sort_values(by='score', ascending=False)[1:11]\n",
        "\n",
        "  # Show results\n",
        "  fig, ax = plt.subplots(2, 5, figsize=(3*3, 2*3))\n",
        "\n",
        "  for i, axis in zip(range(10), ax.flatten()):\n",
        "    img = cv2.imread(get_image_path_by_id(id=reccs['article_id'].iloc[i]))\n",
        "    axis.imshow(img)\n",
        "    axis.get_xaxis().set_visible(False)\n",
        "    axis.get_yaxis().set_visible(False)\n",
        "    #break\n",
        "  fig.suptitle(\"Recommendations of similar items\", fontsize=26)\n",
        "  plt.tight_layout();\n",
        "  fig.savefig('static/recommendation_similar.jpg')\n",
        "\n",
        "  #### Get recommendation of complementary items\n",
        "  # Choose the same index_group_name. I.e. we recommend Ladieswear or Divided if the user has Ladieswear\n",
        "  subset_index = \\\n",
        "    subset_comp[(subset_comp['index_group_name'] == pred_imag_dict['index_group_name']) | \\\n",
        "                (subset_comp['index_group_name'] == 'Divided')]\n",
        "\n",
        "  # Choose the appropriate colour accordingly to the rule\n",
        "  if pred_imag_dict['perceived_colour_master_name'] == 'Beige':\n",
        "    color_to_recommend_lst = ['Blue', 'Purple', 'Brown', 'Mole', 'White', 'Black', 'Yellow', 'Orange']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Black':\n",
        "    color_to_recommend_lst = class_labels_dict['colour'].copy()\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Blue':\n",
        "    color_to_recommend_lst = ['Red', 'Pink', 'Orange', 'Yellow', 'Grey', 'Metal', 'White', 'Black', 'Purple']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Brown' or 'Mole':\n",
        "    color_to_recommend_lst = ['Beige', 'Orange', 'White', 'Black']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Green':\n",
        "    color_to_recommend_lst = ['Orange', 'Purple', 'Grey','Metal', 'White', 'Black', 'Blue']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Grey' or 'Metal':\n",
        "    color_to_recommend_lst = ['Red', 'Pink', 'Blue', 'Purple', 'White', 'Black']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Metal':\n",
        "    color_to_recommend_lst = ['Red', 'Pink', 'Blue', 'Purple', 'White', 'Black']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Orange':\n",
        "    color_to_recommend_lst = ['Green', 'Blue', 'White', 'Black', 'Beige']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Pink':\n",
        "    color_to_recommend_lst = ['Blue', 'Grey', 'White', 'Black', 'Red', 'Beige']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Purple':\n",
        "    color_to_recommend_lst = ['Orange','Grey','Metal', 'Green', 'White', 'Black', 'Blue']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Red':\n",
        "    color_to_recommend_lst = ['Blue', 'Grey', 'White', 'Black', 'Pink', 'Beige']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Turquoise':\n",
        "    color_to_recommend_lst = ['Red', 'Pink', 'Orange', 'Yellow', 'Grey', 'Metal', 'White', 'Black', 'Purple']\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'White':\n",
        "    color_to_recommend_lst = class_labels_dict['colour'].copy()\n",
        "  elif pred_imag_dict['perceived_colour_master_name'] == 'Yellow':\n",
        "    color_to_recommend_lst = ['Green', 'Blue', 'White', 'Black', 'Beige']\n",
        "\n",
        "\n",
        "  subset_index = subset_index[subset_index['perceived_colour_master_name'].isin(color_to_recommend_lst)]\n",
        "\n",
        "  # Choose which type of clothes to recommmend\n",
        "  types_to_recommend_lst = class_labels_dict['product'].copy()\n",
        "\n",
        "  if pred_imag_dict['product_group_name'] == 'Garment Full body':\n",
        "    types_to_recommend_lst.remove('Garment Full body')\n",
        "    types_to_recommend_lst.remove('Garment Lower body')\n",
        "    types_to_recommend_lst.remove('Garment Upper body')\n",
        "  elif pred_imag_dict['product_group_name'] == 'Garment Lower body':\n",
        "    types_to_recommend_lst.remove('Garment Full body')\n",
        "    types_to_recommend_lst.remove('Garment Lower body')\n",
        "  elif pred_imag_dict['product_group_name'] == 'Garment Upper body':\n",
        "    types_to_recommend_lst.remove('Garment Full body')\n",
        "    types_to_recommend_lst.remove('Garment Upper body')\n",
        "\n",
        "  def get_most_similar_vectors(subset_comp, pred_imag_dict, ncols=3):\n",
        "    # Caluclate similarity scores between user image and images from the database\n",
        "    similarity_scores = []\n",
        "    for array in subset_comp[\"embedding\"]:\n",
        "        array = array.reshape(1, -1)\n",
        "        similarity = cosine_similarity(pred_imag_dict['embedding'].reshape(1, -1), array)\n",
        "        similarity_scores.append(similarity[0][0])\n",
        "    subset_comp['score'] = similarity_scores\n",
        "\n",
        "    # Get TOP # similar products\n",
        "    reccs = subset_comp.sort_values(by='score', ascending=False)[:ncols]\n",
        "    return list(reccs['article_id'].values)\n",
        "\n",
        "  id_product_lst = []\n",
        "  ncols=3\n",
        "\n",
        "  for type_to_recommend in types_to_recommend_lst:\n",
        "    subset_group = subset_index[subset_index['product_group_name'] == type_to_recommend]\n",
        "    subset_group = subset_group.copy()\n",
        "    if subset_group.shape[0] == 0:\n",
        "      continue\n",
        "    id_product_lst.append(get_most_similar_vectors(subset_group, pred_imag_dict))\n",
        "    #break\n",
        "\n",
        "  # Flatten list of ID\n",
        "  id_product_lst = [item for sublist in id_product_lst for item in sublist]\n",
        "\n",
        "  # Show results\n",
        "  nrows = int(len(id_product_lst)/3)\n",
        "  fig, ax = plt.subplots(nrows, ncols, figsize=(3*ncols, 3*nrows))\n",
        "\n",
        "  for index, axis in zip(id_product_lst, ax.flatten()):\n",
        "    img = cv2.imread(get_image_path_by_id(id=index))\n",
        "    axis.imshow(img)\n",
        "    axis.get_xaxis().set_visible(False)\n",
        "    axis.get_yaxis().set_visible(False)\n",
        "    #break\n",
        "  fig.suptitle(\"Recommendations of complementary items\", fontsize=26)\n",
        "  plt.tight_layout();\n",
        "  fig.savefig('static/recommendation_complementary.jpg')\n",
        "  return"
      ],
      "metadata": {
        "id": "ltRN-vMWZegg"
      },
      "id": "ltRN-vMWZegg",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yj_muRBEZmun"
      },
      "id": "Yj_muRBEZmun",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8MR83akneUW"
      },
      "id": "G8MR83akneUW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Begining"
      ],
      "metadata": {
        "id": "mEtp8sloZSr-"
      },
      "id": "mEtp8sloZSr-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLASK for Google Colab"
      ],
      "metadata": {
        "id": "UQnWeM0us7ka"
      },
      "id": "UQnWeM0us7ka"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask --quiet\n",
        "!pip install flask-ngrok --quiet\n",
        "print(\"Completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImQr7as9rKkl",
        "outputId": "ef43ff44-7fc5-4e14-cf10-41927250d720"
      },
      "id": "ImQr7as9rKkl",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install ngrok linux version using the following command or you can get the\n",
        "# latest version from its official website- https://dashboard.ngrok.com/get-started/setup\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmHbOm5XtAnj",
        "outputId": "f4f85f02-75fb-4d8d-931f-8683bae6cb6c"
      },
      "id": "DmHbOm5XtAnj",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-15 17:02:37--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 52.202.168.65, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13856790 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.tgz.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.21M  12.9MB/s    in 1.0s    \n",
            "\n",
            "2023-03-15 17:02:39 (12.9 MB/s) - ‘ngrok-stable-linux-amd64.tgz.1’ saved [13856790/13856790]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the downloaded file using the following command \n",
        "!tar -xvf /content/ngrok-stable-linux-amd64.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ofhohtds7FF",
        "outputId": "676e8f39-adb9-4784-ae2d-29a2e2ad5ab1"
      },
      "id": "2Ofhohtds7FF",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paste your AuthToken here and execute this command\n",
        "!./ngrok authtoken 2N3RQFuvD5Is3IuRUEpcV6vfbQS_69QWxoo18dZ6yEsRWZLH8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gs_3ldktMCS",
        "outputId": "387bc2cf-67e9-4c27-d84d-9b159be2aca7"
      },
      "id": "7Gs_3ldktMCS",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import Flask from flask module\n",
        "from flask import Flask, render_template, request\n",
        "\n",
        "# import run_with_ngrok from flask_ngrok to run the app using ngrok\n",
        "from flask_ngrok import run_with_ngrok\n",
        "  \n",
        "app = Flask(__name__) #app name\n",
        "run_with_ngrok(app)\n",
        "  \n",
        "# @app.route(\"/\")\n",
        "# def hello():\n",
        "#     return \"Hello Friends! from Pykit.org. Thank you! for reading this article.\"\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"upload_page.html\")\n",
        "\n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def upload():\n",
        "    if request.method == \"POST\":\n",
        "        file = request.files[\"file\"]\n",
        "        # Do something with the uploaded file here\n",
        "        #filename = os.path.join(app.config[\"UPLOAD_FOLDER\"], file.filename)\n",
        "        file.save('static/user_image.jpg')\n",
        "        \n",
        "        # Read the uploaded image\n",
        "        user_image = cv2.imread('static/user_image.jpg')\n",
        "        # Get recommendations of similar/complementary items\n",
        "        get_recommendations(user_image)        \n",
        "\n",
        "\n",
        "        # create a string variable with the HTML code\n",
        "        html = \"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html>\n",
        "        <head>\n",
        "          <title>Uploaded Images</title>\n",
        "        </head>\n",
        "        <body>\n",
        "          <center><h1>OutfAIt</h1></center>\n",
        "          </br>\n",
        "          <h2>User Image</h2>\n",
        "          <img src=\"static/user_image.jpg\" style=\"width:10%;height:10%;\"><br>\n",
        "          <img src=\"static/recommendation_similar.jpg\" style=\"width:50%;height:50%;\"><br>\n",
        "          <img src=\"static/recommendation_complementary.jpg\" style=\"width:50%;height:50%;\"><br>\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        # create a new HTML file and write the HTML code to it\n",
        "        with open(\"templates/uploaded_images.html\", \"w\") as f:\n",
        "            f.write(html)\n",
        "        return render_template(\"uploaded_images.html\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #app.config[\"UPLOAD_FOLDER\"] = \"/tmp\"\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "oqOas_3HttPw"
      },
      "id": "oqOas_3HttPw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aw6Xt4wYtL8-"
      },
      "id": "aw6Xt4wYtL8-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNPn63jitLW3"
      },
      "id": "WNPn63jitLW3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "33ce96c0-80ad-490a-8fe8-3e195cdedf4c",
      "metadata": {
        "id": "33ce96c0-80ad-490a-8fe8-3e195cdedf4c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2798b193-5f79-4cba-82a3-32789e0e4740",
      "metadata": {
        "id": "2798b193-5f79-4cba-82a3-32789e0e4740"
      },
      "outputs": [],
      "source": [
        "# !git branch\n",
        "# !git add .\n",
        "# !git commit -m \"final notebook for recommendation update\"\n",
        "#!git push origin kuzma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2bab77b3-9305-4aa9-89cf-58a3ced4c18c",
      "metadata": {
        "id": "2bab77b3-9305-4aa9-89cf-58a3ced4c18c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}